)
WC_topicos_twitter
saveWidgetFix(WC_topicos_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_topicos_twitter.html")
saveWidgetFix <- function (widget,file,...) {
## A wrapper to saveWidget which compensates for arguable BUG in
## saveWidget which requires `file` to be in current working
## directory.
wd<-getwd()
on.exit(setwd(wd))
outDir<-dirname(file)
file<-basename(file)
setwd(outDir);
saveWidget(widget,file=file,...)
}
saveWidgetFix(WC_topicos_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_topicos_twitter.html")
webshot::webshot("03_graficas/WC_topicos_twitter.html","03_graficas/WC_topicos_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_topicos_twitter.html","03_graficas/WC_topicos_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
hashtags <- tweets %>%
select(id_str, hashtags)%>%
unnest(cols = hashtags)%>%
mutate(hashtags = stri_trans_general(hashtags, "latin-ascii"))%>%
drop_na() %>%group_by(hashtags) %>% summarise(n = n()) %>%
arrange(desc(n)) %>%
filter(!stri_detect(hashtags, fixed = "covid", case_insensitive = T),
!stri_detect(hashtags, fixed = "coronavirus", case_insensitive = T))
head(hashtags, 20)
WC_hashtags_twitter <- wordcloud2(head(hashtags, 150),
shape = "circle",
size = .65,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 0,#1/pi,
maxRotation = 0,#1/pi,
rotateRatio = 1
)
WC_hashtags_twitter
saveWidgetFix(WC_hashtags_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_hashtags_twitter.html")
webshot::webshot("03_graficas/WC_hashtags_twitter.html","03_graficas/WC_hashtags_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_hashtags_twitter.html","03_graficas/WC_hashtags_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
ats <- tweets %>%
select(id_str, ats)%>%
unnest(cols = ats)%>%
mutate_all(tolower)%>%
drop_na() %>%
group_by(ats) %>%
summarise(n = n()) %>%
arrange(desc(n))%>%
filter(!stri_detect(ats, fixed = "Claudi", case_insensitive = T))
head(ats, 20)
WC_ats_twitter <- wordcloud2(head(ats, 100),
shape = "diamond",
size = 1,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 1/pi,
maxRotation = 1/pi,
rotateRatio = 1
)
WC_ats_twitter
saveWidgetFix(WC_ats_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_ats_twitter.html")
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
headfreq <- head(t_pal_mas_freq, 20)
headhash <- head(hashtags, 20)
headats <- head(ats, 20)
tol <- bind_cols(headhash, headfreq, headats)
saveRDS(tol, "01_datos/tols.rds")
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "html_document", output_file = "RedesSociales")
emm <- readRDS("01_datos/emojis.rds")
View(emm)
Encoding(emm$descr) <- "ISO-8859-1"
View(emm)
emojis <- tweets %>% select(id_str, emojis)%>%unnest(cols = emojis)%>%
drop_na() %>%group_by(emojis) %>% summarise(n = n()) %>% arrange(desc(n))%>%
filter(is.na(as.numeric(emojis)),!str_detect(emojis, "#"),emojis %notin% c("*","!!","‼"))
emojis <- tweets %>% select(id_str, emojis)%>%unnest(cols = emojis)%>%
drop_na() %>%group_by(emojis) %>% summarise(n = n()) %>% arrange(desc(n))%>%
filter(is.na(as.numeric(emojis)),!str_detect(emojis, "#"),emojis %notin% c("*","!!","‼"))
emoji_to_link <- function(x) {
paste0("https://emojipedia.org/emoji/",x) %>%
read_html() %>%
html_nodes("tr td a") %>%
.[1] %>%
html_attr("href") %>%
paste0("https://emojipedia.org/", .) %>%
read_html() %>%
html_node('div[class="vendor-image"] img') %>%
html_attr("src")
}
emoji_to_description <- function(x) {
paste0("https://emojipedia.org/emoji/",x) %>%
read_html() %>%
html_nodes("tr td a") %>%
.[1] %>%
html_attr("href") %>%
paste0("https://emojipedia.org/", .) %>%
read_html() %>%
html_node('section[class="description"]') %>%
html_text()
}
link_to_img <- function(x, size = 25) {
paste0("<img src='", x, "' width='", size, "'/>")
}
thead_emojis <- head(emojis, 30)%>%
mutate(ems1 = stri_extract_all(emojis, regex = "\\p{Emoji_Presentation}"),
ems1 = map(ems1, unique),
len = as.double(map(ems1, length)),
len = ifelse(is.na(ems1), NA_real_, len),
ems2 = stri_extract_all(emojis, regex = "\\p{Emoji_Modifier}"),
ems3 = stri_extract_all(emojis, regex = "\\p{Emoji_Modifier_Base}"),
ems4 = stri_extract_all(emojis, regex = "\\p{Emoji_Component}"),
ems4 = ifelse(is.na(ems1), emojis, NA_character_),
count= stri_count(emojis, regex = "\\p{Emoji}"),
count1=stri_count(emojis, regex = "\\p{Emoji_Presentation}"),
count2=stri_count(emojis, regex = "\\p{Emoji_Modifier}"),
count3=stri_count(emojis, regex = "\\p{Emoji_Modifier_Base}"),
count4=stri_count(emojis, regex = "\\p{Emoji_Component}"),
countif = case_when(
count==1 | len==1| count1 == 1| count2 == 1| count3 == 1| count4 == 1 ~ as.integer(1),
!is.na(ems4) ~ stri_count(emojis, regex="\\p{Emoji}"),
T ~ as.integer(count)
),
finalems = ifelse(count==1, emojis, NA),
finalems = ifelse(ifelse(is.na(len), F, len == 1), ems1, finalems),
finalems = ifelse(countif>1, emojis, finalems),
finalems = ifelse(is.na(finalems), ifelse(countif==1, ems3, finalems), finalems),
)%>%
transmute(family = ifelse(is.na(ems4), "OpenSansEmoji" , "EmojiOne"),
emojis = finalems,
n = n)
thead_emojis <- thead_emojis %>%
mutate(url = map_chr(emojis, slowly(~plyr::try_default(emoji_to_link(.x), NA, quiet = T), rate_delay(1))),
descr = map_chr(emojis, slowly(~plyr::try_default(emoji_to_description(.x), NA, quiet = T), rate_delay(1))),
label = link_to_img(url))
thead_emojis <- thead_emojis%>%
mutate(emojis = ifelse(is.na(url),stri_extract_all(emojis, regex = "\\p{Emoji_Presentation}"), emojis))%>%
unnest(emojis)%>%
mutate(url = ifelse(is.na(url),map_chr(emojis, slowly(~plyr::try_default(emoji_to_link(.x), NA), rate_delay(1))), url),
descr = ifelse(is.na(descr),map_chr(emojis, slowly(~plyr::try_default(emoji_to_description(.x), NA), rate_delay(1))), descr),
label = link_to_img(url),
`Número de Tweets`=n
)
key <- jsonlite::read_json("apikey/contraseñaTranslateEmojis.json")
thead_emojis <- translate(dataset = thead_emojis,content.field = "descr", google.api.key = key$key, source.lang = "en", target.lang = "es") %>%
mutate(
descr = stri_replace_last(translatedContent, fixed = " Copie y pegue este emoji: Copiar", ""),
descr = gsub('&quot;', '', descr)
) %>% select(-translatedContent) %>%
mutate(
descr = stri_replace_all(descr, fixed = "Ã¡", replacement = "á"),
descr = stri_replace_all(descr, fixed = "Ã©", replacement = "é"),
descr = stri_replace_all(descr, fixed = "Ã³", replacement = "ó"),
descr = stri_replace_all(descr, fixed = "Ãº", replacement = "ú"),
descr = stri_replace_all(descr, fixed = "Ã±", replacement = "ñ"),
descr = stri_replace_all(descr, fixed = "Ã", replacement = "í"),
)
View(thead_emojis)
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "html_document", output_file = "RedesSociales")
thead_emojis <- readRDS("01_datos/emojis.rds")
thead_emojis2 <- read_csv("01_datos/emojis.csv")
View(thead_emojis2)
thead_emojis2 <- read_csv2("01_datos/emojis.csv")
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "html_document", output_file = "RedesSociales")
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "html_document", output_file = "RedesSociales")
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "html_document", output_file = "RedesSociales")
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "html_document", output_file = "RedesSociales")
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "html_document", output_file = "RedesSociales")
tweets <- readRDS(file = "01_datos/tweets.rds")
require(wordcloud2)
custom_stop_words <- enframe(tm::stopwords("es")) %>%
bind_rows(enframe(c( "t", "rt"))) %>%
rename(palabra = value)
t_pal_mas_freq <- tweets %>%
# Extraer palabras de título y agrupar por título
unnest_tokens(input = "texto", output = "palabra") %>%
# Quitar stopwords
anti_join(custom_stop_words) %>%
# Contar palabras
count(palabra, sort = TRUE) %>%
# Quitar missing values
drop_na() %>%
# palabras a mayúsculas
mutate(palabra = toupper(palabra))
t_pal_mas_freq <- t_pal_mas_freq %>% filter(!str_detect(palabra,"CLAU"))
head(t_pal_mas_freq, 20)
WC_topicos_twitter <- wordcloud2(head(t_pal_mas_freq, 100),
shape = "diamond",
size = .9,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 1/pi,
maxRotation = 1/pi,
rotateRatio = 1
)
WC_topicos_twitter
saveWidgetFix(WC_topicos_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_topicos_twitter.html")
webshot::webshot("03_graficas/WC_topicos_twitter.html","03_graficas/WC_topicos_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_topicos_twitter.html","03_graficas/WC_topicos_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
hashtags <- tweets %>%
select(id_str, hashtags)%>%
unnest(cols = hashtags)%>%
mutate(hashtags = stri_trans_general(hashtags, "latin-ascii"))%>%
drop_na() %>%group_by(hashtags) %>% summarise(n = n()) %>%
arrange(desc(n)) %>%
filter(!stri_detect(hashtags, fixed = "covid", case_insensitive = T),
!stri_detect(hashtags, fixed = "coronavirus", case_insensitive = T))
head(hashtags, 20)
WC_hashtags_twitter <- wordcloud2(head(hashtags, 150),
shape = "circle",
size = .65,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 0,#1/pi,
maxRotation = 0,#1/pi,
rotateRatio = 1
)
WC_hashtags_twitter
saveWidgetFix(WC_hashtags_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_hashtags_twitter.html")
webshot::webshot("03_graficas/WC_hashtags_twitter.html","03_graficas/WC_hashtags_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_hashtags_twitter.html","03_graficas/WC_hashtags_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
ats <- tweets %>%
select(id_str, ats)%>%
unnest(cols = ats)%>%
mutate_all(tolower)%>%
drop_na() %>%
group_by(ats) %>%
summarise(n = n()) %>%
arrange(desc(n))%>%
filter(!stri_detect(ats, fixed = "Claudi", case_insensitive = T))
head(ats, 20)
WC_ats_twitter <- wordcloud2(head(ats, 100),
shape = "diamond",
size = 1,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 1/pi,
maxRotation = 1/pi,
rotateRatio = 1
)
WC_ats_twitter
saveWidgetFix(WC_ats_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_ats_twitter.html")
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
headfreq <- head(t_pal_mas_freq, 20)
headhash <- head(hashtags, 20)
headats <- head(ats, 20)
tol <- bind_cols(headhash, headfreq, headats)
View(tol)
## Build PDFs
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
### Build Webpage
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "html_document", output_file = "RedesSociales")
readRDS("01_datos/tols.rds")
tweets <- readRDS(file = "01_datos/tweets.rds")
## Build PDFs
rm(list = ls(all.names = TRUE))
custom_stop_words <- enframe(tm::stopwords("es")) %>%
bind_rows(enframe(c( "t", "rt"))) %>%
rename(palabra = value)
t_pal_mas_freq <- tweets %>%
# Extraer palabras de título y agrupar por título
unnest_tokens(input = "texto", output = "palabra") %>%
# Quitar stopwords
anti_join(custom_stop_words) %>%
# Contar palabras
count(palabra, sort = TRUE) %>%
# Quitar missing values
drop_na() %>%
# palabras a mayúsculas
mutate(palabra = toupper(palabra))
require(wordcloud2)
tweets <- readRDS(file = "01_datos/tweets.rds")
tweets <- readRDS("01_datos/covid_02ABR20.rds") %>%
as_tibble() %>%
as_tibble() %>%
distinct(id_str, .keep_all = T)%>%
mutate(
hashtags = stri_extract_all(text, regex = "#[[:alnum:]_]+"),
ats = stri_extract_all(text, regex = "@[[:alnum:]_]+"),
emojis = stri_extract_all_charclass(text, "\\p{EMOJI}"),
texto = gsub(text, pattern = " ", replacement = "_"),
texto = gsub(texto, pattern = "[[:space:]]", replacement = ""),
texto = gsub(texto, pattern = "_", replacement = " "),
texto = gsub(texto, pattern = "ª", replacement = ""),
texto = gsub(texto, pattern = "[0-9]+|[[:punct:]]|\\(.*\\)", replacement = ""),
texto = gsub(texto, pattern = "https[^[:space:]]*", replacement = ""),
texto = gsub(texto, pattern = "[^[:alpha:][:space:]]*", replacement = ""),
texto = gsub(texto, pattern = "[[:punct:]]", replacement = ""),
texto = gsub(texto, pattern = "  ", replacement = " "),
texto = trimws(texto),
texto = str_replace_all(texto, pattern = "rt",
replacement = ""),
fecha = as.POSIXct(created,
format = "%Y-%m-%d %T") - hours(7),
RT = stri_detect(text, fixed = "RT"),
replied_TO = ifelse(RT, stri_extract_first(text, regex = "@[[:alnum:]_]+"), "")
) %>% filter(fecha>as.POSIXct("2020-03-30", format = "%Y-%m-%d")) %>%
mutate(
test = as.character(hashtags),
keep = ifelse(
str_detect(tolower(test), "covid"), 1,0
)
) %>%
filter(keep==1) %>% select(-test) %>% select(-keep)
t_pal_mas_freq <- tweets %>%
# Extraer palabras de título y agrupar por título
unnest_tokens(input = "texto", output = "palabra") %>%
# Quitar stopwords
anti_join(custom_stop_words) %>%
# Contar palabras
count(palabra, sort = TRUE) %>%
# Quitar missing values
drop_na() %>%
# palabras a mayúsculas
mutate(palabra = toupper(palabra))
t_pal_mas_freq <- t_pal_mas_freq %>% filter(!str_detect(palabra,"CLAU"))
head(t_pal_mas_freq, 20)
WC_topicos_twitter <- wordcloud2(head(t_pal_mas_freq, 100),
shape = "diamond",
size = .9,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 1/pi,
maxRotation = 1/pi,
rotateRatio = 1
)
WC_topicos_twitter
saveWidgetFix(WC_topicos_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_topicos_twitter.html")
saveWidgetFix <- function (widget,file,...) {
## A wrapper to saveWidget which compensates for arguable BUG in
## saveWidget which requires `file` to be in current working
## directory.
wd<-getwd()
on.exit(setwd(wd))
outDir<-dirname(file)
file<-basename(file)
setwd(outDir);
saveWidget(widget,file=file,...)
}
saveWidgetFix(WC_topicos_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_topicos_twitter.html")
webshot::webshot("03_graficas/WC_topicos_twitter.html","03_graficas/WC_topicos_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_topicos_twitter.html","03_graficas/WC_topicos_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
hashtags <- tweets %>%
select(id_str, hashtags)%>%
unnest(cols = hashtags)%>%
mutate(hashtags = stri_trans_general(hashtags, "latin-ascii"))%>%
drop_na() %>%group_by(hashtags) %>% summarise(n = n()) %>%
arrange(desc(n)) %>%
filter(!stri_detect(hashtags, fixed = "covid", case_insensitive = T),
!stri_detect(hashtags, fixed = "coronavirus", case_insensitive = T))
head(hashtags, 20)
WC_hashtags_twitter <- wordcloud2(head(hashtags, 150),
shape = "circle",
size = .65,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 0,#1/pi,
maxRotation = 0,#1/pi,
rotateRatio = 1
)
WC_hashtags_twitter
saveWidgetFix(WC_hashtags_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_hashtags_twitter.html")
webshot::webshot("03_graficas/WC_hashtags_twitter.html","03_graficas/WC_hashtags_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_hashtags_twitter.html","03_graficas/WC_hashtags_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
ats <- tweets %>%
select(id_str, ats)%>%
unnest(cols = ats)%>%
mutate_all(tolower)%>%
drop_na() %>%
group_by(ats) %>%
summarise(n = n()) %>%
arrange(desc(n))%>%
filter(!stri_detect(ats, fixed = "Claudi", case_insensitive = T))
head(ats, 20)
WC_ats_twitter <- wordcloud2(head(ats, 100),
shape = "diamond",
size = 1,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 1/pi,
maxRotation = 1/pi,
rotateRatio = 1
)
WC_ats_twitter
saveWidgetFix(WC_ats_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_ats_twitter.html")
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
headfreq <- head(t_pal_mas_freq, 20)
headhash <- head(hashtags, 20)
headats <- head(ats, 20)
tol <- bind_cols(headhash, headfreq, headats)
saveRDS(tol, "01_datos/tols.rds")
WC_ats_twitter <- wordcloud2(head(ats, 100),
shape = "diamond",
size = .8,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 1/pi,
maxRotation = 1/pi,
rotateRatio = 1
)
WC_ats_twitter
saveWidgetFix(WC_ats_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_ats_twitter.html")
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
WC_ats_twitter <- wordcloud2(head(ats, 100),
shape = "diamond",
size = .6,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 1/pi,
maxRotation = 1/pi,
rotateRatio = 1
)
WC_ats_twitter
saveWidgetFix(WC_ats_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_ats_twitter.html")
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
WC_ats_twitter <- wordcloud2(head(ats, 100),
shape = "diamond",
size = .7,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 1/pi,
maxRotation = 1/pi,
rotateRatio = 1
)
WC_ats_twitter
saveWidgetFix(WC_ats_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_ats_twitter.html")
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
headfreq <- head(t_pal_mas_freq, 20)
headhash <- head(hashtags, 20)
headats <- head(ats, 20)
tol <- bind_cols(headhash, headfreq, headats)
View(tol)
saveRDS(tol, "01_datos/tols.rds")
## Build PDFs
rm(list = ls(all.names = TRUE))
## Build PDFs
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
### Build Webpage
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "html_document", output_file = "RedesSociales")
