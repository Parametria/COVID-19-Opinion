colour="black") +
geom_point() +
scale_color_continuous(NULL, NULL, NULL)+
scale_size(NULL, NULL, NULL)+
scale_x_datetime(date_breaks = "3 day", date_labels =  "%b/%d %I:00%p")+
theme_ipsum(grid="Y") +
labs(title=str_wrap(fiuf, width = 80),
subtitle = str_wrap(fiuff, width = 80),
y="Número de tweets",
x="",
caption=fiuffi) +
theme(plot.title = element_text(size = 35),
plot.subtitle = element_text(size = 30),
plot.caption = element_text(size = 20),
axis.title.x = element_text(size = 20),
axis.text.y = element_text(size = 20),
axis.text.x = element_text(angle = 90))
# Paquetes ----
library(webshot)
require(wordcloud2)
require(tm)
require(tidytext)
require(stringi)
require(readxl)
require(lubridate)
require(zoo)
require(wordcloud)
require(haven)
require(foreign)
require(htmlwidgets)
require(topicmodels)
require(Rmpfr)
require(slam)
require(igraph)
require(ggraph)
require(gplots)
require(gganimate)
require(ggcorrplot)
require(gridExtra)
require(ggthemes)
require(hrbrthemes)
require(magick)
require(scales)
require(RColorBrewer)
require(beepr)
require(devtools)
require(jsonlite)
require(tidyverse)
require(RSQLite)
require(emojifont)
require(ggrepel)
load.emojifont("OpenSansEmoji.ttf")
load.emojifont("EmojiOne.ttf")
# Datos ----
con <- dbConnect(SQLite(),"SynologyDrive/Drive/Code/tweets_20ABR20.db")
tb <- dbListTables(con)
d1 <- readRDS("~/Desktop/extra/COVID-19-Opinion/01_datos/covid_2.rds")
d1 <- readRDS("~/Desktop/extra/COVID-19-Opinion/01_datos/covid_02ABR20.rds")
d2 <- dbReadTable(con, tb[1])%>%
mutate(covid = stri_detect(text, fixed = "covid", case_insensitive = T))%>%
filter(covid)
dbDisconnect(con)
rm(tb, con)
d <- full_join(d2, d1)%>%distinct(id_str, .keep_all = T)
saveRDS(d, "~/SynologyDrive/Drive/Code/Parametría/Twitter-COVID/01_datos/covid05MAY20.rds")
saveRDS(d, "~/Desktop/extra/COVID-19-Opinion/01_datos/covid05MAY20.rds")
setwd("~/Desktop/extra/COVID-19-Opinion/")
tweets <- readRDS("01_datos/covid05MAY20.rds") %>%
as_tibble() %>%
as_tibble() %>%
distinct(id_str, .keep_all = T)%>%
mutate(
hashtags = stri_extract_all(text, regex = "#[[:alnum:]_]+"),
ats = stri_extract_all(text, regex = "@[[:alnum:]_]+"),
emojis = stri_extract_all_charclass(text, "\\p{EMOJI}"),
texto = gsub(text, pattern = " ", replacement = "_"),
texto = gsub(texto, pattern = "[[:space:]]", replacement = ""),
texto = gsub(texto, pattern = "_", replacement = " "),
texto = gsub(texto, pattern = "ª", replacement = ""),
texto = gsub(texto, pattern = "[0-9]+|[[:punct:]]|\\(.*\\)", replacement = ""),
texto = gsub(texto, pattern = "https[^[:space:]]*", replacement = ""),
texto = gsub(texto, pattern = "[^[:alpha:][:space:]]*", replacement = ""),
texto = gsub(texto, pattern = "[[:punct:]]", replacement = ""),
texto = gsub(texto, pattern = "  ", replacement = " "),
texto = trimws(texto),
texto = str_replace_all(texto, pattern = "rt",
replacement = ""),
fecha = as.POSIXct(created,
format = "%Y-%m-%d %T") - hours(7),
RT = stri_detect(text, fixed = "RT"),
replied_TO = ifelse(RT, stri_extract_first(text, regex = "@[[:alnum:]_]+"), "")
) %>% filter(fecha>as.POSIXct("2020-03-30", format = "%Y-%m-%d")) %>%
mutate(
test = as.character(hashtags),
keep = ifelse(
str_detect(tolower(test), "covid"), 1,0
)
) %>%
filter(keep==1) %>% select(-test) %>% select(-keep)
saveRDS(tweets, "01_datos/tweets.rds")
# extrafont::loadfonts(device="win")
require(rvest, quietly = T)
## remotes::install_github("wilkelab/ggtext")
require(ggtext, quietly = T)
## devtools::install_github("hadley/emo")
require(emo, quietly = T)
require(hrbrthemes, quietly = T)
require(tidytext, quietly = T)
require(emojifont)
require(ggrepel, quietly = T)
require(stringi, quietly = T)
require(ggthemes, quietly = T)
require(lubridate, quietly = T)
require(plotly, quietly = T)
require(RColorBrewer, quietly = T)
#require(hrbthemes, quietly = T)
require(tidyverse, quietly = T)
require(htmlwidgets, quietly = T)
require(knitr, quietly = T)
require(translateR, quietly = T)
require(htmltools, quietly = T)
load.emojifont("OpenSansEmoji.ttf")
load.emojifont("EmojiOne.ttf")
caption <- "Elaboración propia con datos de Twitter | <a href='https://twitter.com/Parametria'>@parametria</a>"
caption1 <- "Elaboración propia con datos de Twitter | Parametría"
saveWidgetFix <- function (widget,file,...) {
## A wrapper to saveWidget which compensates for arguable BUG in
## saveWidget which requires `file` to be in current working
## directory.
wd<-getwd()
on.exit(setwd(wd))
outDir<-dirname(file)
file<-basename(file)
setwd(outDir);
saveWidget(widget,file=file,...)
}
rm_words <-
function(string, words) {
stopifnot(is.character(string), is.character(words))
spltted <- strsplit(string, " ", fixed = TRUE) # fixed = TRUE for speedup
vapply(spltted, function(x) paste(x[!tolower(x) %in% words], collapse = " "), character(1))
}
# Aplicar str_wrap a objetos dentro de otras funciones (como scale_x_discrete(labels=equis))
strwrap_obj <- function(x) {
str_wrap(x, width = 10)
}
BigramTokenizer <-
function(x) {
unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
}
!file.exists("01_datos/tweets.rds")
custom_stop_words <- enframe(tm::stopwords("es")) %>%
bind_rows(enframe(c( "t", "rt"))) %>%
rename(palabra = value)
t_pal_mas_freq <- tweets %>%
# Extraer palabras de título y agrupar por título
unnest_tokens(input = "texto", output = "palabra") %>%
# Quitar stopwords
anti_join(custom_stop_words) %>%
# Contar palabras
count(palabra, sort = TRUE) %>%
# Quitar missing values
drop_na() %>%
# palabras a mayúsculas
mutate(palabra = toupper(palabra))
t_pal_mas_freq <- t_pal_mas_freq %>% filter(!str_detect(palabra,"CLAU"))
head(t_pal_mas_freq, 20)
WC_topicos_twitter <- wordcloud2(head(t_pal_mas_freq, 100),
shape = "diamond",
size = .9,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 1/pi,
maxRotation = 1/pi,
rotateRatio = 1
)
WC_topicos_twitter
saveWidgetFix(WC_topicos_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_topicos_twitter.html")
webshot::webshot("03_graficas/WC_topicos_twitter.html","03_graficas/WC_topicos_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_topicos_twitter.html","03_graficas/WC_topicos_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
hashtags <- tweets %>%
select(id_str, hashtags)%>%
unnest(cols = hashtags)%>%
mutate(hashtags = stri_trans_general(hashtags, "latin-ascii"))%>%
drop_na() %>%group_by(hashtags) %>% summarise(n = n()) %>%
arrange(desc(n)) %>%
filter(!stri_detect(hashtags, fixed = "covid", case_insensitive = T),
!stri_detect(hashtags, fixed = "coronavirus", case_insensitive = T))
head(hashtags, 20)
WC_hashtags_twitter <- wordcloud2(head(hashtags, 150),
shape = "circle",
size = .65,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 0,#1/pi,
maxRotation = 0,#1/pi,
rotateRatio = 1
)
WC_hashtags_twitter
WC_hashtags_twitter <- wordcloud2(head(hashtags, 150),
shape = "circle",
size = .5,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 0,#1/pi,
maxRotation = 0,#1/pi,
rotateRatio = 1
)
WC_hashtags_twitter
WC_hashtags_twitter <- wordcloud2(head(hashtags, 150),
shape = "circle",
size = .4,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 0,#1/pi,
maxRotation = 0,#1/pi,
rotateRatio = 1
)
WC_hashtags_twitter
saveWidgetFix(WC_hashtags_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_hashtags_twitter.html")
webshot::webshot("03_graficas/WC_hashtags_twitter.html","03_graficas/WC_hashtags_twitter.png",
delay =5, vwidth = 1000, vheight=800)
WC_hashtags_twitter <- wordcloud2(head(hashtags, 150),
shape = "circle",
size = .7,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 0,#1/pi,
maxRotation = 0,#1/pi,
rotateRatio = 1
)
WC_hashtags_twitter
saveWidgetFix(WC_hashtags_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_hashtags_twitter.html")
webshot::webshot("03_graficas/WC_hashtags_twitter.html","03_graficas/WC_hashtags_twitter.png",
delay =5, vwidth = 1000, vheight=800)
WC_hashtags_twitter <- wordcloud2(head(hashtags, 150),
shape = "circle",
size = .6,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 0,#1/pi,
maxRotation = 0,#1/pi,
rotateRatio = 1
)
WC_hashtags_twitter
saveWidgetFix(WC_hashtags_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_hashtags_twitter.html")
webshot::webshot("03_graficas/WC_hashtags_twitter.html","03_graficas/WC_hashtags_twitter.png",
delay =5, vwidth = 1000, vheight=800)
head(hashtags, 20)
webshot::webshot("03_graficas/WC_hashtags_twitter.html","03_graficas/WC_hashtags_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
ats <- tweets %>%
select(id_str, ats)%>%
unnest(cols = ats)%>%
mutate_all(tolower)%>%
drop_na() %>%
group_by(ats) %>%
summarise(n = n()) %>%
arrange(desc(n))%>%
filter(!stri_detect(ats, fixed = "Claudi", case_insensitive = T))
head(ats, 20)
WC_ats_twitter <- wordcloud2(head(ats, 100),
shape = "diamond",
size = .7,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 1/pi,
maxRotation = 1/pi,
rotateRatio = 1
)
WC_ats_twitter
saveWidgetFix(WC_ats_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_ats_twitter.html")
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
headfreq <- head(t_pal_mas_freq, 20)
headhash <- head(hashtags, 20)
headats <- head(ats, 20)
tol <- bind_cols(headhash, headfreq, headats)
saveRDS(tol, "01_datos/tols.rds")
## Build PDFs
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
minday <- format(min(tweets$fecha), "%d")
minmonth <- format(min(tweets$fecha), "%m")
maxday <- format(max(tweets$fecha), "%d")
maxmonth <- format(max(tweets$fecha), "%m")
months <- list(
"01"="enero",
"02"="febrero",
"03"="marzo",
"04"="abril",
"05"="mayo",
"06"="junio",
"07"="julio",
"08"="agosto",
"09"="septiembre",
"10"="octubre",
"11"="noviembre",
"12"="diciembre"
)
if(maxmonth == minmonth){
fectoprint <- paste(minday, "al", maxday,"de", months[minmonth])
} else {
fectoprint <-   paste(minday,"de",months[minmonth] ,"al", maxday,"de", months[maxmonth])
}
tweets <- readRDS("01_datos/tweets.rds")
minday <- format(min(tweets$fecha), "%d")
minmonth <- format(min(tweets$fecha), "%m")
maxday <- format(max(tweets$fecha), "%d")
maxmonth <- format(max(tweets$fecha), "%m")
months <- list(
"01"="enero",
"02"="febrero",
"03"="marzo",
"04"="abril",
"05"="mayo",
"06"="junio",
"07"="julio",
"08"="agosto",
"09"="septiembre",
"10"="octubre",
"11"="noviembre",
"12"="diciembre"
)
if(maxmonth == minmonth){
fectoprint <- paste(minday, "al", maxday,"de", months[minmonth])
} else {
fectoprint <-   paste(minday,"de",months[minmonth] ,"al", maxday,"de", months[maxmonth])
}
titulo <- "Frecuencia de tweets que mencionan al #COVID19mx"
subtitulo <- "Tweets agrupados por hora del 31 de marzo al 20 de abril de 2020"
tweets_sum <- tweets %>%
group_by(month = month(fecha),day = day(fecha), hour = hour(fecha)) %>%
summarise(`Número de Tweets` = n(),
retweets = sum(as.numeric(retweet_count), na.rm = T ))%>%
mutate(Fecha= as.POSIXct(paste0(month," " ,day, " ", hour), format = "%m %d %H"))
ur <- ggplot(data = tweets_sum,
aes(size = `Número de Tweets`,
y = `Número de Tweets`,
color = `Número de Tweets`,
x = Fecha)) +
geom_smooth(method = "loess",
show.legend = F,
colour="black") +
geom_point() +
scale_color_continuous(NULL, NULL, NULL)+
scale_size(NULL, NULL, NULL)+
scale_x_datetime(date_breaks = "1 day", date_labels =  "%b/%d")+
theme_ipsum(grid="Y") +
labs(title=str_wrap(titulo, width = 80),
subtitle = str_wrap(subtitulo, width = 80),
y="Número de tweets",
x="",
caption=caption1)+
theme(plot.title = element_text(size = 35),
plot.subtitle = element_text(size = 25),
plot.caption = element_text(size = 20),
axis.title.x = element_text(size = 20),
axis.text.y = element_text(size = 20),
axis.text.x = element_text(angle = 90))
ggsave("03_graficas/linea_tiempo_tweets.pdf", plot = ur,
width = 15, height = 10, dpi = 100)
ur <- ggplot(data = tweets %>%
group_by(month = month(fecha),day = day(fecha), hour = hour(fecha)) %>%
summarise(`Número de Tweets` = n(),
retweets = sum(as.numeric(retweet_count), na.rm = T ))%>%
mutate(Fecha= as.POSIXct(paste0(month," " ,day, " ", hour), format = "%m %d %H")),
aes(size = `Número de Tweets`,
y = `Número de Tweets`,
color = `Número de Tweets`,
x = Fecha)) +
geom_point() +
scale_color_continuous(NULL, NULL, NULL)+
scale_size(NULL, NULL, NULL)+
scale_x_datetime(date_breaks = "1 day", date_labels =  "%b/%d %I:00%p")+
theme_ipsum(grid="Y") +
labs(title=str_wrap(titulo, width = 80),
subtitle = str_wrap(subtitulo, width = 80),
y="Número de tweets",
x="",
caption=caption1) +
theme(plot.title = element_text(size = 20),
plot.subtitle = element_text(size = 15),
plot.caption = element_text(size = 10),
axis.title.x = element_text(size = 10),
axis.text.y = element_text(size = 10),
axis.text.x = element_text(angle = 45))
if(params$view_html) {
plotly <- ggplotly(ur+theme(axis.text.x = element_text(size=8)),height=600,
tooltip = c("x", "y"),
dynamicTicks = TRUE
)%>%
rangeslider() %>%
layout(title = list(text = "",
y = 1.1),
hovermode = "x",
tickvalues ="",
annotations = list(x = 1, y = 0,
text = caption,
showarrow = F,
xref='paper',
yref='paper',
xanchor='right',
yanchor='auto',
xshift=0,
yshift=0,
font=list(size=15, color="red")))
saveWidgetFix(plotly,libdir = "graph_dependencies", selfcontained = F, file="03_graficas/linea_tiempo_tweets.html")
div(plotly, class="myplot", align = "center")
} else if(params$view_pdf ){
include_graphics(path ="03_graficas/linea_tiempo_tweets.png", auto_pdf = T)
}
readRDS("01_datos/tols.rds")
afinn <- readRDS("01_datos/DiccionarioUNAfin.rds")%>%
filter(!is.na(mean)) %>% rename(Puntuacion = mean)
asce <- afinn %>% distinct(root, .keep_all = T)%>%
select(-Palabra)%>%arrange(Puntuacion)
general_afinn <- tweets%>%select(id_str, texto, fecha)%>%
mutate(id = 1:length(texto),
id = formatC(id, width = 3, format="d", flag="0")) %>%
unnest_tokens(input = "texto", output = "Palabra") %>%
inner_join(afinn,., by = "Palabra") %>%
#mutate(Tipo = ifelse(Puntuacion > 0, "Positiva", "Negativa"))  %>%
group_by(month = month(fecha), day = day(fecha), hour = hour(fecha), id) %>%
summarise(puntuacion = sum(Puntuacion)) %>%
group_by(month, day, hour) %>%
summarise(puntuacion = mean(puntuacion),
n = n()) %>%
mutate(puntuacion = ifelse(is.na(puntuacion), 0, puntuacion),
colour = ifelse(puntuacion>0,"positivo",
ifelse(puntuacion<0,"negativo","neutral")),
alpha = abs(puntuacion))%>%
ungroup()%>%
mutate(Fecha = as.POSIXct(paste0(month, " " ,day, " ", hour), format = "%m %d %H"),
`Número de tweets` = n)
titulo <- "Análisis de sentimiento en tweets de COVID19"
subtitulo1 <- "Cada círculo representa un día; el tamaño del círculo indica la cantidad de tweets encontrados por día. Una puntuación mayor a cero representa un sentimiento promedio positivo; una menor, un negativo."
subtitulo <- "Cada círculo representa un día; el tamaño del círculo indica la cantidad de tweets encontrados por día. <br>Una puntuación mayor a cero representa un sentimiento promedio positivo; una menor, un negativo."
ur <- ggplot(general_afinn ,
aes(x = Fecha,
y = puntuacion,
col = colour,
size=`Número de tweets`)) +
geom_point()+
scale_x_datetime(date_breaks = "1 day", date_labels =  "%b/%d %I%p")+
scale_color_manual(values = c("#FC4E07", "grey",  "#00AFBB")) +
scale_size_continuous("Sentimiento",
guide = guide_legend(override.aes = list(colour = "#E7B800"))) +
guides(color = F) +
xlab("") + ylab("Puntuación")  +
labs(title = str_wrap(titulo, width = 90),
subtitle= str_wrap(subtitulo1, width = 90),
caption=caption1,
x="Tiempo",
y="Sentimiento") +
theme_ipsum() +
scale_fill_distiller("",palette="Spectral") +
theme(plot.title = element_text(size = 25),
plot.subtitle = element_text(size = 15),
plot.caption = element_text(size = 12),
legend.key.size = unit(1, "cm"),
legend.title = element_text(size = 10),
legend.text = element_text(size = 10),
axis.title.x = element_text(size = 15),
axis.text.y = element_text(size = 15),
axis.text.x = element_text(angle = 90))
ggsave(filename = "03_graficas/linea_tiempo_sentimiento_tweets.pdf",plot = ur + geom_smooth(method="loess", show.legend = F, colour="black") + geom_point(),
width = 15, height = 10, dpi = 100)
tweets <- readRDS("01_datos/covid05MAY20.rds") %>%
as_tibble() %>%
as_tibble() %>%
distinct(id_str, .keep_all = T)%>%
mutate(
hashtags = stri_extract_all(text, regex = "#[[:alnum:]_]+"),
ats = stri_extract_all(text, regex = "@[[:alnum:]_]+"),
emojis = stri_extract_all_charclass(text, "\\p{EMOJI}"),
texto = gsub(text, pattern = " ", replacement = "_"),
texto = gsub(texto, pattern = "[[:space:]]", replacement = ""),
texto = gsub(texto, pattern = "_", replacement = " "),
texto = gsub(texto, pattern = "ª", replacement = ""),
texto = gsub(texto, pattern = "[0-9]+|[[:punct:]]|\\(.*\\)", replacement = ""),
texto = gsub(texto, pattern = "https[^[:space:]]*", replacement = ""),
texto = gsub(texto, pattern = "[^[:alpha:][:space:]]*", replacement = ""),
texto = gsub(texto, pattern = "[[:punct:]]", replacement = ""),
texto = gsub(texto, pattern = "  ", replacement = " "),
texto = trimws(texto),
texto = str_replace_all(texto, pattern = "rt",
replacement = ""),
fecha = as.POSIXct(created,
format = "%Y-%m-%d %T") - hours(7),
RT = stri_detect(text, fixed = "RT"),
replied_TO = ifelse(RT, stri_extract_first(text, regex = "@[[:alnum:]_]+"), "")
) %>% filter(fecha>as.POSIXct("2020-03-30", format = "%Y-%m-%d"))
saveRDS(tweets, "01_datos/tweets.rds")
## Build PDFs
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
### Build Webpage
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "html_document", output_file = "RedesSociales")
