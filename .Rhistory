knit(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd", output = "all()")
knit(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd")
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd",output_format = "all" )
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd",output_format = c("pdf", "html") )
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd",output_format = c("pdf_document", "html_document") )
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd", output_format = c("pdf_document", "html_document") , params )
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd", output_format = c("pdf_document", "html_document") , params )
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd", output_format = c("pdf_document", "html_document") , params )
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd", output_format = c("pdf_document", "html_document") , params )
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd", output_format = "pdf_document" , params )
knit_with_parameters('~/Desktop/extra/covid19_mex_Reportes/Unt.Rmd')
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd", output_format = "pdf_document" , params )
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd", output_format = "pdf_document" , params )
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd", output_format = "pdf_document" , params )
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd", output_format = "pdf_document" , params )
---
title: "Reporte COVID-19"
author: '[Parametría](http://parametria.com.mx/)'
date: "`r format(Sys.time(), '%d/%m/%Y')`"
output:
html_document:
collapsed: no
css: style.css
df_print: paged
include:
after_body: footer.html
in_header: header.html
number_sections: no
theme: lumen
toc: no
toc_depth: 1
toc_float: yes
pdf_document:
toc: no
toc_depth: '1'
mail: lorenzoln@parametria.com.mx
github: LorenzoLeon/covid19_mex_Reportes
twitter: lolo7no
---
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd", output_format = "all" , params )
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd", output_format = "all" , params,  output_file = "unt")
rmarkdown::render(input = "Desktop/extra/covid19_mex_Reportes/Unt.Rmd", output_format = "all",  output_file = "unt")
require(tidyverse)
require(RSQLite)
# Datos ----
con <- dbConnect(SQLite(),"SynologyDrive/Drive/Code/Parametría/tweets_20MAR20.db")
tb <- dbListTables(con)
d1 <- readRDS("Desktop/extra/COVID-19-Opinion/01_datos/covid_2.rds")
d2 <- dbReadTable(con, tb[2])%>%
mutate(covid = stri_detect(text, fixed = "covid", case_insensitive = T))%>%
filter(covid)
require(stringi)
d2 <- dbReadTable(con, tb[2])%>%
mutate(covid = stri_detect(text, fixed = "covid", case_insensitive = T))%>%
filter(covid)
dbDisconnect(con)
rm(tb, con)
d <- full_join(d2, d1)%>%distinct(id_str, .keep_all = T)
saveRDS(d, "01_datos/covid_2.rds")
saveRDS(d, "SynologyDrive/Drive/Code/Parametría/Twitter-COVID/01_datos/covid_02ABR20.rds")
data <- d %>%
as_tibble() %>%
distinct(id_str, .keep_all = T)%>%
mutate(
hashtags = stri_extract_all(text, regex = "#[[:alnum:]_]+"),
ats = stri_extract_all(text, regex = "@[[:alnum:]_]+"),
emojis = stri_extract_all_charclass(text, "\\p{EMOJI}"),
texto = gsub(text, pattern = " ", replacement = "_"),
texto = gsub(texto, pattern = "[[:space:]]", replacement = ""),
texto = gsub(texto, pattern = "_", replacement = " "),
texto = gsub(texto, pattern = "ª", replacement = ""),
texto = gsub(texto, pattern = "[0-9]+|[[:punct:]]|\\(.*\\)", replacement = ""),
texto = gsub(texto, pattern = "https[^[:space:]]*", replacement = ""),
texto = gsub(texto, pattern = "[^[:alpha:][:space:]]*", replacement = ""),
texto = gsub(texto, pattern = "[[:punct:]]", replacement = ""),
texto = gsub(texto, pattern = "  ", replacement = " "),
texto = trimws(texto),
texto = str_replace_all(texto, pattern = "rt",
replacement = ""),
fecha = as.POSIXct(created,
format = "%Y-%m-%d %T") - hours(7),
RT = stri_detect(text, fixed = "RT"),
replied_TO = ifelse(RT, stri_extract_first(text, regex = "@[[:alnum:]_]+"), "")
) %>% filter(fecha>as.POSIXct("2020-03-15", format = "%Y-%m-%d"))
# 0. Frecuencia de tuits ----
fiuf <- "Frecuencia de tuits que mencionan al "
fiuff <- "#COVID19mx\nTuits agrupados por hora del 15 de marzo a 19 de marzo de 2020"
ggplot(data = data %>%
group_by(month = month(fecha),day = day(fecha), hour = hour(fecha)) %>%
summarise(`Número de Tweets` = n(),
retweets = sum(as.numeric(retweet_count), na.rm = T ))%>%
mutate(Fecha= as.POSIXct(paste0(month," " ,day, " ", hour), format = "%m %d %H")),
aes(size = `Número de Tweets`,
y = `Número de Tweets`,
color = `Número de Tweets`,
x = Fecha)) +
geom_smooth(method = "loess",
show.legend = F,
colour="black") +
geom_point() +
scale_color_continuous(NULL, NULL, NULL)+
scale_size(NULL, NULL, NULL)+
scale_x_datetime(date_breaks = "3 day", date_labels =  "%b/%d %I:00%p")+
theme_ipsum(grid="Y") +
labs(title=str_wrap(fiuf, width = 80),
subtitle = str_wrap(fiuff, width = 80),
y="Número de tweets",
x="",
caption=fiuffi) +
theme(plot.title = element_text(size = 35),
plot.subtitle = element_text(size = 30),
plot.caption = element_text(size = 20),
axis.title.x = element_text(size = 20),
axis.text.y = element_text(size = 20),
axis.text.x = element_text(angle = 90))
require(wordcloud2)
require(tm)
require(tidytext)
require(stringi)
require(readxl)
require(lubridate)
require(zoo)
require(wordcloud)
require(haven)
require(foreign)
require(htmlwidgets)
require(topicmodels)
require(Rmpfr)
require(slam)
require(igraph)
require(ggraph)
require(gplots)
require(gganimate)
require(ggcorrplot)
require(gridExtra)
require(ggthemes)
require(hrbrthemes)
require(magick)
require(scales)
require(RColorBrewer)
require(beepr)
require(devtools)
require(jsonlite)
require(tidyverse)
require(RSQLite)
require(emojifont)
require(ggrepel)
ggplot(data = data %>%
group_by(month = month(fecha),day = day(fecha), hour = hour(fecha)) %>%
summarise(`Número de Tweets` = n(),
retweets = sum(as.numeric(retweet_count), na.rm = T ))%>%
mutate(Fecha= as.POSIXct(paste0(month," " ,day, " ", hour), format = "%m %d %H")),
aes(size = `Número de Tweets`,
y = `Número de Tweets`,
color = `Número de Tweets`,
x = Fecha)) +
geom_smooth(method = "loess",
show.legend = F,
colour="black") +
geom_point() +
scale_color_continuous(NULL, NULL, NULL)+
scale_size(NULL, NULL, NULL)+
scale_x_datetime(date_breaks = "3 day", date_labels =  "%b/%d %I:00%p")+
theme_ipsum(grid="Y") +
labs(title=str_wrap(fiuf, width = 80),
subtitle = str_wrap(fiuff, width = 80),
y="Número de tweets",
x="",
caption=fiuffi) +
theme(plot.title = element_text(size = 35),
plot.subtitle = element_text(size = 30),
plot.caption = element_text(size = 20),
axis.title.x = element_text(size = 20),
axis.text.y = element_text(size = 20),
axis.text.x = element_text(angle = 90))
data <- d %>%
as_tibble() %>%
distinct(id_str, .keep_all = T)%>%
mutate(
hashtags = stri_extract_all(text, regex = "#[[:alnum:]_]+"),
ats = stri_extract_all(text, regex = "@[[:alnum:]_]+"),
emojis = stri_extract_all_charclass(text, "\\p{EMOJI}"),
texto = gsub(text, pattern = " ", replacement = "_"),
texto = gsub(texto, pattern = "[[:space:]]", replacement = ""),
texto = gsub(texto, pattern = "_", replacement = " "),
texto = gsub(texto, pattern = "ª", replacement = ""),
texto = gsub(texto, pattern = "[0-9]+|[[:punct:]]|\\(.*\\)", replacement = ""),
texto = gsub(texto, pattern = "https[^[:space:]]*", replacement = ""),
texto = gsub(texto, pattern = "[^[:alpha:][:space:]]*", replacement = ""),
texto = gsub(texto, pattern = "[[:punct:]]", replacement = ""),
texto = gsub(texto, pattern = "  ", replacement = " "),
texto = trimws(texto),
texto = str_replace_all(texto, pattern = "rt",
replacement = ""),
fecha = as.POSIXct(created,
format = "%Y-%m-%d %T") - hours(7),
RT = stri_detect(text, fixed = "RT"),
replied_TO = ifelse(RT, stri_extract_first(text, regex = "@[[:alnum:]_]+"), "")
) %>% filter(fecha>as.POSIXct("2020-03-15", format = "%Y-%m-%d"))
ggplot(data = data %>%
group_by(month = month(fecha),day = day(fecha), hour = hour(fecha)) %>%
summarise(`Número de Tweets` = n(),
retweets = sum(as.numeric(retweet_count), na.rm = T ))%>%
mutate(Fecha= as.POSIXct(paste0(month," " ,day, " ", hour), format = "%m %d %H")),
aes(size = `Número de Tweets`,
y = `Número de Tweets`,
color = `Número de Tweets`,
x = Fecha)) +
geom_smooth(method = "loess",
show.legend = F,
colour="black") +
geom_point() +
scale_color_continuous(NULL, NULL, NULL)+
scale_size(NULL, NULL, NULL)+
scale_x_datetime(date_breaks = "3 day", date_labels =  "%b/%d %I:00%p")+
theme_ipsum(grid="Y") +
labs(title=str_wrap(fiuf, width = 80),
subtitle = str_wrap(fiuff, width = 80),
y="Número de tweets",
x="",
caption=fiuffi) +
theme(plot.title = element_text(size = 35),
plot.subtitle = element_text(size = 30),
plot.caption = element_text(size = 20),
axis.title.x = element_text(size = 20),
axis.text.y = element_text(size = 20),
axis.text.x = element_text(angle = 90))
fiuffi <- "Fuente: API Twitter \n @parametria | @guzmart_ | @lolo7no"
ggplot(data = data %>%
group_by(month = month(fecha),day = day(fecha), hour = hour(fecha)) %>%
summarise(`Número de Tweets` = n(),
retweets = sum(as.numeric(retweet_count), na.rm = T ))%>%
mutate(Fecha= as.POSIXct(paste0(month," " ,day, " ", hour), format = "%m %d %H")),
aes(size = `Número de Tweets`,
y = `Número de Tweets`,
color = `Número de Tweets`,
x = Fecha)) +
geom_smooth(method = "loess",
show.legend = F,
colour="black") +
geom_point() +
scale_color_continuous(NULL, NULL, NULL)+
scale_size(NULL, NULL, NULL)+
scale_x_datetime(date_breaks = "3 day", date_labels =  "%b/%d %I:00%p")+
theme_ipsum(grid="Y") +
labs(title=str_wrap(fiuf, width = 80),
subtitle = str_wrap(fiuff, width = 80),
y="Número de tweets",
x="",
caption=fiuffi) +
theme(plot.title = element_text(size = 35),
plot.subtitle = element_text(size = 30),
plot.caption = element_text(size = 20),
axis.title.x = element_text(size = 20),
axis.text.y = element_text(size = 20),
axis.text.x = element_text(angle = 90))
setwd("Desktop/extra/COVID-19-Opinion/")
tweets <- readRDS(file = "01_datos/tweets.rds")
# extrafont::loadfonts(device="win")
require(rvest, quietly = T)
## remotes::install_github("wilkelab/ggtext")
require(ggtext, quietly = T)
## devtools::install_github("hadley/emo")
require(emo, quietly = T)
require(hrbrthemes, quietly = T)
require(tidytext, quietly = T)
require(emojifont)
require(ggrepel, quietly = T)
require(stringi, quietly = T)
require(ggthemes, quietly = T)
require(lubridate, quietly = T)
require(plotly, quietly = T)
require(RColorBrewer, quietly = T)
#require(hrbthemes, quietly = T)
require(tidyverse, quietly = T)
require(htmlwidgets, quietly = T)
require(knitr, quietly = T)
require(translateR, quietly = T)
require(htmltools, quietly = T)
load.emojifont("OpenSansEmoji.ttf")
load.emojifont("EmojiOne.ttf")
caption <- "Elaboración propia con datos de Twitter | <a href='https://twitter.com/Parametria'>@parametria</a>"
caption1 <- "Elaboración propia con datos de Twitter | Parametría"
saveWidgetFix <- function (widget,file,...) {
## A wrapper to saveWidget which compensates for arguable BUG in
## saveWidget which requires `file` to be in current working
## directory.
wd<-getwd()
on.exit(setwd(wd))
outDir<-dirname(file)
file<-basename(file)
setwd(outDir);
saveWidget(widget,file=file,...)
}
rm_words <-
function(string, words) {
stopifnot(is.character(string), is.character(words))
spltted <- strsplit(string, " ", fixed = TRUE) # fixed = TRUE for speedup
vapply(spltted, function(x) paste(x[!tolower(x) %in% words], collapse = " "), character(1))
}
# Aplicar str_wrap a objetos dentro de otras funciones (como scale_x_discrete(labels=equis))
strwrap_obj <- function(x) {
str_wrap(x, width = 10)
}
BigramTokenizer <-
function(x) {
unlist(lapply(ngrams(words(x), 2), paste, collapse = " "), use.names = FALSE)
}
if(!file.exists("01_datos/tweets.rds")){
tweets <- readRDS("01_datos/covid_20MAY20.rds") %>%
as_tibble() %>%
distinct(id_str, .keep_all = T)%>%
mutate(
hashtags = stri_extract_all(text, regex = "#[[:alnum:]_]+"),
ats = stri_extract_all(text, regex = "@[[:alnum:]_]+"),
emojis = stri_extract_all_charclass(text, "\\p{EMOJI}"),
texto = stri_replace_all(text, regex = "#[[:alnum:]_]+", ""),
texto = stri_replace_all(texto, regex = "@[[:alnum:]_]+", ""),
texto = stri_replace_all_charclass(texto, "\\p{EMOJI}", ""),
texto = gsub(texto, pattern = " ", replacement = "_"),
texto = gsub(texto, pattern = "[[:space:]]", replacement = ""),
texto = gsub(texto, pattern = "_", replacement = " "),
texto = gsub(texto, pattern = "ª", replacement = ""),
texto = gsub(texto, pattern = "[0-9]+|[[:punct:]]|\\(.*\\)", replacement = ""),
texto = gsub(texto, pattern = "https[^[:space:]]*", replacement = ""),
texto = gsub(texto, pattern = "[^[:alpha:][:space:]]*", replacement = ""),
texto = gsub(texto, pattern = "[[:punct:]]", replacement = ""),
texto = gsub(texto, pattern = "  ", replacement = " "),
texto = trimws(texto),
texto = str_replace_all(texto, pattern = "rt",
replacement = ""),
fecha = as.POSIXct(created,
format = "%Y-%m-%d %T") - hours(7),
RT = stri_detect(text, fixed = "RT"),
replied_TO = ifelse(RT, stri_extract_first(text, regex = "@[[:alnum:]_]+"), "")
) %>% filter(fecha>as.POSIXct("2020-03-30", format = "%Y-%m-%d"))
saveRDS(tweets, "01_datos/tweets.rds")
} else {
tweets <- readRDS("01_datos/tweets.rds")
}
require(wordcloud2)
custom_stop_words <- enframe(tm::stopwords("es")) %>%
bind_rows(enframe(c( "t", "rt"))) %>%
rename(palabra = value)
t_pal_mas_freq <- tweets %>%
# Extraer palabras de título y agrupar por título
unnest_tokens(input = "texto", output = "palabra") %>%
# Quitar stopwords
anti_join(custom_stop_words) %>%
# Contar palabras
count(palabra, sort = TRUE) %>%
# Quitar missing values
drop_na() %>%
# palabras a mayúsculas
mutate(palabra = toupper(palabra))
t_pal_mas_freq <- t_pal_mas_freq %>% filter(!str_detect(palabra,"CLAU"))
head(t_pal_mas_freq, 20)
WC_topicos_twitter <- wordcloud2(head(t_pal_mas_freq, 100),
shape = "diamond",
size = .9,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 1/pi,
maxRotation = 1/pi,
rotateRatio = 1
)
WC_topicos_twitter
saveWidgetFix(WC_topicos_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_topicos_twitter.html")
webshot::webshot("03_graficas/WC_topicos_twitter.html","03_graficas/WC_topicos_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_topicos_twitter.html","03_graficas/WC_topicos_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
hashtags <- tweets %>%
select(id_str, hashtags)%>%
unnest(cols = hashtags)%>%
mutate(hashtags = stri_trans_general(hashtags, "latin-ascii"))%>%
drop_na() %>%group_by(hashtags) %>% summarise(n = n()) %>%
arrange(desc(n)) %>%
filter(!stri_detect(hashtags, fixed = "covid", case_insensitive = T),
!stri_detect(hashtags, fixed = "coronavirus", case_insensitive = T))
head(hashtags, 20)
WC_hashtags_twitter <- wordcloud2(head(hashtags, 150),
shape = "circle",
size = .6,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 0,#1/pi,
maxRotation = 0,#1/pi,
rotateRatio = 1
)
WC_hashtags_twitter
saveWidgetFix(WC_hashtags_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_hashtags_twitter.html")
webshot::webshot("03_graficas/WC_hashtags_twitter.html","03_graficas/WC_hashtags_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_hashtags_twitter.html","03_graficas/WC_hashtags_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
ats <- tweets %>%
select(id_str, ats)%>%
unnest(cols = ats)%>%
mutate_all(tolower)%>%
drop_na() %>%
group_by(ats) %>%
summarise(n = n()) %>%
arrange(desc(n))%>%
filter(!stri_detect(ats, fixed = "Claudi", case_insensitive = T))
head(ats, 20)
WC_ats_twitter <- wordcloud2(head(ats, 100),
shape = "diamond",
size = .7,
#color = brewer.pal(n = 6, name = "Spectral"),
fontWeight = "bold",
minRotation = 1/pi,
maxRotation = 1/pi,
rotateRatio = 1
)
WC_ats_twitter
saveWidgetFix(WC_ats_twitter,libdir = "graph_dependencies", selfcontained = F,
file = "03_graficas/WC_ats_twitter.html")
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.png",
delay =5, vwidth = 1000, vheight=800)
webshot::webshot("03_graficas/WC_ats_twitter.html","03_graficas/WC_ats_twitter.pdf",
delay =5, vwidth = 1000, vheight=800)
headfreq <- head(t_pal_mas_freq, 20)
headhash <- head(hashtags, 20)
headats <- head(ats, 20)
tol <- bind_cols(headhash, headfreq, headats)
saveRDS(tol, "01_datos/tols.rds")
## Build PDFs
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
## Build PDFs
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
## Build PDFs
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
setwd("~/Desktop/extra/COVID-19-Opinion/")
## Build PDFs
rmarkdown::render(input = "AnalisisParametria.Rmd",
output_format = "pdf_document",  output_file = "AnalisisParametria")
rm(list = ls(all.names = TRUE))
## Build PDFs
rmarkdown::render(input = "AnalisisParametria.Rmd",
output_format = "pdf_document",  output_file = "AnalisisParametria")
rm(list = ls(all.names = TRUE))
## Build PDFs
rmarkdown::render(input = "AnalisisParametria.Rmd",
output_format = "pdf_document",  output_file = "AnalisisParametria")
rm(list = ls(all.names = TRUE))
## Build PDFs
rmarkdown::render(input = "AnalisisParametria.Rmd",
output_format = "pdf_document",  output_file = "AnalisisParametria")
rm(list = ls(all.names = TRUE))
## Build PDFs
rmarkdown::render(input = "AnalisisParametria.Rmd",
output_format = "pdf_document",  output_file = "AnalisisParametria")
rm(list = ls(all.names = TRUE))
## Build PDFs
rmarkdown::render(input = "AnalisisParametria.Rmd",
output_format = "pdf_document",  output_file = "AnalisisParametria")
rm(list = ls(all.names = TRUE))
## Build PDFs
rmarkdown::render(input = "AnalisisParametria.Rmd",
output_format = "pdf_document",  output_file = "AnalisisParametria")
rm(list = ls(all.names = TRUE))
### Build Webpage
rmarkdown::render(input = "AnalisisParametria.Rmd",
output_format = "html_document", output_file = "index")
### Build Webpage
rmarkdown::render(input = "AnalisisParametria.Rmd",
output_format = "html_document", output_file = "index")
## Build PDFs
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
## Build PDFs
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
### Build Webpage
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "html_document", output_file = "RedesSociales")
## Build PDFs
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
### Build Webpage
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "html_document", output_file = "RedesSociales")
## Build PDFs
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
### Build Webpage
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "html_document", output_file = "RedesSociales")
## Build PDFs
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "pdf_document",  output_file = "RedesSociales")
### Build Webpage
rm(list = ls(all.names = TRUE))
rmarkdown::render(input = "RedesSociales.Rmd",
output_format = "html_document", output_file = "RedesSociales")
